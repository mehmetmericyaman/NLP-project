{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"zgnbyktanr/turkish-psychological-classification-for-nlp\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QklLMejyJN4A",
        "outputId": "14bff65c-ddcc-49b4-d3fd-f27aa3febe35"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/zgnbyktanr/turkish-psychological-classification-for-nlp/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "XBxhKwRaG2LA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk stopwords yükleyelim\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('turkish'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok_2xvNAG9PN",
        "outputId": "cdf87b14-96a1-4921-fa04-8105c03d231c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Dosya yolundaki dosyaları listeleyin\n",
        "dataset_path = '/root/.cache/kagglehub/datasets/zgnbyktanr/turkish-psychological-classification-for-nlp/versions/1'\n",
        "files = os.listdir(dataset_path)\n",
        "print(files)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_MCJHvmJ9Uu",
        "outputId": "ec28ad69-7801-48b5-9cb4-8f89d530b1a4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dataset.csv', 'test.xlsx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Doğru dosya yolunu kullanarak CSV dosyasını okuyun\n",
        "file_path = '/root/.cache/kagglehub/datasets/zgnbyktanr/turkish-psychological-classification-for-nlp/versions/1/dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# İlk birkaç satırı inceleyin\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bt-_hHxK0A7",
        "outputId": "57e56cf9-1cd2-4d4a-d2f2-f6ebf42a6175"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  İlişkilerimde aşırı derecede idealize edip son...      6\n",
            "1  Bir gece uykumda yürüyüp dolaptan kıyafetlerim...      2\n",
            "2  Kumar borçlarım yüzünden evliliğim tehlikede. ...      4\n",
            "3  Uykum çok hafif ve en ufak bir sesle bile uyan...      2\n",
            "4  Kumar borçlarımı ödemek için çaldığım paraları...      4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Veri Ön İşleme\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "x0LSFsfRM9O_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Özellik Çıkarımı\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))  # Unigrams ve Bigrams\n",
        "X = tfidf.fit_transform(df['cleaned_text']).toarray()\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "ylahgF3PNDrh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veri setini ayıralım\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "zNnSWQihNGwO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE uygulayalım\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59TnC9_HNJhM",
        "outputId": "a390d775-f5ac-4a06-e6c5-7acdeafd4093"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lojistik Regresyon Modeli\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_logistic = logistic_model.predict(X_test)\n",
        "print(\"Lojistik Regresyon Doğruluk Skoru:\", accuracy_score(y_test, y_pred_logistic))\n",
        "print(\"Lojistik Regresyon Sınıflandırma Raporu:\\n\", classification_report(y_test, y_pred_logistic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKt_bcGPNQAy",
        "outputId": "ca60a2a6-a116-4cf6-9f5b-0f93f284a792"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lojistik Regresyon Doğruluk Skoru: 0.7993079584775087\n",
            "Lojistik Regresyon Sınıflandırma Raporu:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      1.00      0.92         6\n",
            "           1       0.88      1.00      0.93        14\n",
            "           2       0.95      0.95      0.95        20\n",
            "           3       1.00      1.00      1.00         8\n",
            "           4       0.82      0.90      0.86        52\n",
            "           5       0.70      0.70      0.70        10\n",
            "           6       0.90      0.60      0.72        15\n",
            "           7       0.67      0.40      0.50         5\n",
            "           8       0.78      0.78      0.78        18\n",
            "           9       0.92      0.71      0.80        17\n",
            "          10       0.64      0.68      0.66        34\n",
            "          11       0.84      0.79      0.82        34\n",
            "          12       1.00      0.43      0.60         7\n",
            "          13       0.59      0.80      0.68        20\n",
            "          14       0.75      0.88      0.81        17\n",
            "          15       1.00      0.75      0.86        12\n",
            "\n",
            "    accuracy                           0.80       289\n",
            "   macro avg       0.83      0.77      0.79       289\n",
            "weighted avg       0.81      0.80      0.80       289\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sinir Ağı Modeli\n",
        "input_dim = X_train_resampled.shape[1]  # TF-IDF özellik boyutu\n",
        "\n",
        "nn_model = Sequential([\n",
        "    Dense(128, activation='relu', input_dim=input_dim),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(np.unique(y)), activation='softmax')  # Çoklu sınıf için softmax kullanılıyor\n",
        "])\n",
        "\n",
        "nn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbRXN3OLNUI8",
        "outputId": "1343f922-5285-4140-f7d0-84b5952071cb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli eğitelim\n",
        "nn_model.fit(X_train_resampled, y_train_resampled, epochs=20, batch_size=16, validation_split=0.5, verbose=1)\n",
        "\n",
        "# Test veri seti ile tahmin yapalım\n",
        "y_pred_nn = np.argmax(nn_model.predict(X_test), axis=1)\n",
        "\n",
        "print(\"Sinir Ağı Doğruluk Skoru:\", accuracy_score(y_test, y_pred_nn))\n",
        "print(\"Sinir Ağı Sınıflandırma Raporu:\\n\", classification_report(y_test, y_pred_nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbhrK-44Nilt",
        "outputId": "dd43cbc7-960f-4bed-facc-4b52a60cc7a1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9936 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 4.5906e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9945 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 4.4946e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9979 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 4.2521e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.0165 - val_accuracy: 1.0000 - val_loss: 5.4653e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9960 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 5.0438e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9968 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 4.3611e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9921 - loss: 0.0165 - val_accuracy: 1.0000 - val_loss: 7.2167e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 3.8586e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9893 - loss: 0.0291 - val_accuracy: 1.0000 - val_loss: 3.8811e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9946 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 4.2476e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9945 - loss: 0.0176 - val_accuracy: 1.0000 - val_loss: 4.7967e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9940 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 1.0314e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9963 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 6.3447e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9959 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 5.1552e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 6.4917e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9967 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 5.5504e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9947 - loss: 0.0181 - val_accuracy: 1.0000 - val_loss: 4.2286e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 4.0805e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9949 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 6.1495e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9936 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 6.6460e-05\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Sinir Ağı Doğruluk Skoru: 0.7750865051903114\n",
            "Sinir Ağı Sınıflandırma Raporu:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      1.00      0.75         6\n",
            "           1       0.87      0.93      0.90        14\n",
            "           2       1.00      1.00      1.00        20\n",
            "           3       0.73      1.00      0.84         8\n",
            "           4       0.87      0.92      0.90        52\n",
            "           5       0.73      0.80      0.76        10\n",
            "           6       0.56      0.60      0.58        15\n",
            "           7       0.50      0.40      0.44         5\n",
            "           8       0.78      0.78      0.78        18\n",
            "           9       0.91      0.59      0.71        17\n",
            "          10       0.61      0.65      0.63        34\n",
            "          11       0.94      0.85      0.89        34\n",
            "          12       0.60      0.86      0.71         7\n",
            "          13       0.59      0.50      0.54        20\n",
            "          14       0.77      0.59      0.67        17\n",
            "          15       0.82      0.75      0.78        12\n",
            "\n",
            "    accuracy                           0.78       289\n",
            "   macro avg       0.74      0.76      0.74       289\n",
            "weighted avg       0.78      0.78      0.77       289\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kullanıcıdan cümle alıp tahmin yapma\n",
        "label_dict = {\n",
        "    0: \"Suicidal Thoughts\",\n",
        "    1: \"Eating Disorders\",\n",
        "    2: \"Sleep Disorders\",\n",
        "    3: \"Sexual Disorders\",\n",
        "    4: \"Addictions\",\n",
        "    5: \"Anger Control Disorders\",\n",
        "    6: \"Borderline\",\n",
        "    7: \"Psychosomatic Disorders\",\n",
        "    8: \"OCD (Obsessive-Compulsive Disorder)\",\n",
        "    9: \"Behavioral Disorders in Children\",\n",
        "    10: \"Depression and Related Disorders\",\n",
        "    11: \"Family and Relationship Issues\",\n",
        "    12: \"Sports Psychology\",\n",
        "    13: \"Attention Deficit and Hyperactivity Disorder (ADHD)\",\n",
        "    14: \"Trauma\",\n",
        "    15: \"Paraphilic Disorders\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "ZMR_qxhaNjtt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_sentences():\n",
        "    sentences = []\n",
        "    while True:\n",
        "        print(\"\\nSeçenekler:\")\n",
        "        print(\"1. Cümle Gir\")\n",
        "        print(\"2. Sonucu Gör\")\n",
        "        print(\"3. Çıkış\")\n",
        "        choice = input(\"Bir seçenek girin: \")\n",
        "\n",
        "        if choice == '1':\n",
        "            sentence = input(\"Lütfen bir cümle girin: \")\n",
        "            sentences.append(sentence)\n",
        "            print(f\"Cümle eklendi: {sentence}\")\n",
        "        elif choice == '2':\n",
        "            if not sentences:\n",
        "                print(\"Lütfen önce cümle girin!\")\n",
        "                continue\n",
        "            cleaned_sentences = [clean_text(sentence) for sentence in sentences]\n",
        "            vectorized_sentences = tfidf.transform(cleaned_sentences).toarray()\n",
        "\n",
        "            logistic_predictions = logistic_model.predict(vectorized_sentences)\n",
        "            nn_predictions = np.argmax(nn_model.predict(vectorized_sentences), axis=1)\n",
        "\n",
        "            print(\"\\nSonuçlar:\")\n",
        "            for i, sentence in enumerate(sentences):\n",
        "                logistic_class = label_dict.get(logistic_predictions[i], \"Bilinmeyen Rahatsızlık\")\n",
        "                nn_class = label_dict.get(nn_predictions[i], \"Bilinmeyen Rahatsızlık\")\n",
        "                print(f\"Cümle {i+1}: '{sentence}'\")\n",
        "                print(f\"  Lojistik Regresyon Tahmini: {logistic_predictions[i]} ({logistic_class})\")\n",
        "                print(f\"  Sinir Ağı Tahmini: {nn_predictions[i]} ({nn_class})\")\n",
        "\n",
        "            sentences.clear()\n",
        "        elif choice == '3':\n",
        "            print(\"\\u00c7ıkılıyor...\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Geçersiz seçenek. Lütfen tekrar deneyin.\")\n",
        "\n",
        "classify_sentences()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VsMHPHtNrQE",
        "outputId": "a209914a-884d-492e-e64f-4e2bc34ae467"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Seçenekler:\n",
            "1. Cümle Gir\n",
            "2. Sonucu Gör\n",
            "3. Çıkış\n",
            "Bir seçenek girin: intihar etmek istiyorum\n",
            "Geçersiz seçenek. Lütfen tekrar deneyin.\n",
            "\n",
            "Seçenekler:\n",
            "1. Cümle Gir\n",
            "2. Sonucu Gör\n",
            "3. Çıkış\n",
            "Bir seçenek girin: 1\n",
            "Lütfen bir cümle girin: intihar etmek istiyorum\n",
            "Cümle eklendi: intihar etmek istiyorum\n",
            "\n",
            "Seçenekler:\n",
            "1. Cümle Gir\n",
            "2. Sonucu Gör\n",
            "3. Çıkış\n",
            "Bir seçenek girin: 2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\n",
            "Sonuçlar:\n",
            "Cümle 1: 'intihar etmek istiyorum'\n",
            "  Lojistik Regresyon Tahmini: 0 (Suicidal Thoughts)\n",
            "  Sinir Ağı Tahmini: 10 (Depression and Related Disorders)\n",
            "\n",
            "Seçenekler:\n",
            "1. Cümle Gir\n",
            "2. Sonucu Gör\n",
            "3. Çıkış\n",
            "Bir seçenek girin: 3\n",
            "Çıkılıyor...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}